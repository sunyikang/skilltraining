{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages\n",
    "Let's load the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version: 2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print('tf version:', tf.__version__)\n",
    "\n",
    "tf.keras.backend.set_image_data_format('channels_first')\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "np.set_printoptions(threshold=5)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model(input_size, output_size):\n",
    "    '''\n",
    "    Builds the layers for LSTM model.\n",
    "\n",
    "    args:\n",
    "        - input_size: (tuple) (sequence len, num keypoints)\n",
    "        - output_size: (int) number of classes\n",
    "    '''\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(input_size, activation='relu'),\n",
    "        tf.keras.layers.Dense(output_size)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss(label, pred):\n",
    "    return criterion(label, pred)\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(x)\n",
    "        loss = compute_loss(t, preds)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_acc(t, preds)\n",
    "\n",
    "    return preds\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, t):\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    test_loss(loss)\n",
    "    test_acc(t, preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function train_step at 0x1a38821dd0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function train_step at 0x1a38821dd0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function compute_loss at 0x1a38821ef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function compute_loss at 0x1a38821ef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /Users/yikangsun/opt/anaconda3/envs/cnn/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1a3b6ee5f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1a3b6ee5f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function test_step at 0x1a388af050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function test_step at 0x1a388af050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "Epoch: 5, Valid Cost: 10.588, Valid Acc: 0.218\n",
      "Epoch: 10, Valid Cost: nan, Valid Acc: 0.158\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load data\n",
    "'''\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = (x_train.reshape(-1, 784) / 255).astype(np.float32)\n",
    "x_test = (x_test.reshape(-1, 784) / 255).astype(np.float32)\n",
    "y_train = np.eye(10)[y_train].astype(np.float32)\n",
    "y_test = np.eye(10)[y_test].astype(np.float32)\n",
    "\n",
    "'''\n",
    "Build model\n",
    "'''\n",
    "model = build_mlp_model(200, 10)\n",
    "criterion = tf.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "'''\n",
    "Train model\n",
    "'''\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "train_acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_loss = tf.keras.metrics.Mean()\n",
    "test_acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    _x_train, _y_train = shuffle(x_train, y_train, random_state=42)\n",
    "\n",
    "    for batch in range(n_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "        train_step(_x_train[start:end], _y_train[start:end])\n",
    "\n",
    "    if epoch % 5 == 4 or epoch == epochs - 1:\n",
    "        preds = test_step(x_test, y_test)\n",
    "        print('Epoch: {}, Valid Cost: {:.3f}, Valid Acc: {:.3f}'.format(\n",
    "            epoch+1,\n",
    "            test_loss.result(),\n",
    "            test_acc.result()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "IaknP",
   "launcher_item_id": "5UMr4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('cnn': conda)",
   "language": "python",
   "name": "python37464bitcnncondac06c1f92f8a44f02ae576031040f0065"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
